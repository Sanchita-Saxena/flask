{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "import random\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os\n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__, template_folder='template', static_folder='static')\n",
    "model=load_model(r'EmotionEmergency.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest import result\n",
    "\n",
    "\n",
    "@app.route('/predict_',methods=['GET','POST'])\n",
    "def predict_():\n",
    "\n",
    "    # get file from POST request and save it\n",
    "    # audio_file = request.files[\"file\"]\n",
    "    # file_name = str(random.randint(0, 100000))\n",
    "    # audio_file.save(file_name)\n",
    "    audio_file = r\"C:\\Users\\saxen\\Downloads\\output.wav\"\n",
    "    # result_list=[]\n",
    "    # count_list=[]\n",
    "    # livepredictions=\"\"\n",
    "    try:\n",
    "        r = sr.Recognizer()\n",
    "        # open the file\n",
    "        with sr.AudioFile(audio_file) as source:\n",
    "        # listen for the data (load audio to memory)\n",
    "            # r.adjust_for_ambient_noise(source)\n",
    "            audio_data = r.listen(source)\n",
    "        # recognize (convert from speech to text)\n",
    "            text = r.recognize_google(audio_data)\n",
    "            print(text.casefold())\n",
    "            speech_text= text.casefold()\n",
    "    except sr.UnknownValueError:\n",
    "        # result_list =[\"Blank Call\", \"\", \"\"]\n",
    "        # count_list=[\"\", \"\", \"\"]\n",
    "        # df = pd.DataFrame(zip(result_list,count_list))\n",
    "        # livepredictions=\"Blank Call\"\n",
    "    # if livepredictions == \"Blank Call\":\n",
    "        os.remove(audio_file)\n",
    "        return render_template('result.html', prediction_text='{}'.format(\"Blank Call\"), text_emotion1='{}'.format(\"Blank Call\"),text_emotion2='{}'.format(\"\"),text_emotion3='{}'.format(\"\"))\n",
    "    if speech_text!=\"\":\n",
    "        Features = pd.read_csv(r'D:\\SER\\E2\\features_Emergency.csv')\n",
    "        Y = Features['labels'].values\n",
    "        encoder = OneHotEncoder()\n",
    "        Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n",
    "        \n",
    "        # NOISE\n",
    "        def noise(data):\n",
    "            noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "            data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "            return data\n",
    "        # # STRETCH\n",
    "        # def stretch(data, rate=0.8):\n",
    "        #     return librosa.effects.time_stretch(data, rate)\n",
    "        # # PITCH\n",
    "        # def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "        #     return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "\n",
    "        def feat_ext(data):\n",
    "            mfcc = np.mean(librosa.feature.mfcc(y=data, sr=22050).T, axis=0)\n",
    "            return mfcc\n",
    "\n",
    "        def get_feat(path):\n",
    "            data, sample_rate = librosa.load(path, duration=5, offset=0.6)\n",
    "            # normal data\n",
    "            res1 = feat_ext(data)\n",
    "            result = np.array(res1)\n",
    "            #data with noise\n",
    "            noise_data = noise(data)\n",
    "            res2 = feat_ext(noise_data)\n",
    "            result = np.vstack((result, res2))\n",
    "            return result\n",
    "\n",
    "        try:\n",
    "            feature = get_feat(audio_file)\n",
    "            test =np.expand_dims(feature, axis=2)\n",
    "            livepreds = model.predict(test)\n",
    "            livepredictions = (encoder.inverse_transform((livepreds)))\n",
    "        except ValueError:\n",
    "            livepredictions = ['Blank Call']\n",
    "\n",
    "        dataset = pd.read_csv(r'WORDS_EMOTIONS.csv')\n",
    "        # dataset = dataset.decode('ISO-8859-1', 'ignore')\n",
    "        dataset.astype({'Phrases':'string', 'Emotions':'string'}).dtypes\n",
    "        X = dataset['Phrases']\n",
    "        y = dataset['Emotions']\n",
    "        emotion_list=[]\n",
    "        for i in range(len(X)):\n",
    "            if X[i] in speech_text:\n",
    "                emotion_list.append(y[i])  \n",
    "        \n",
    "        # if len(emotion_list)>0:\n",
    "        try:\n",
    "            count_angry=emotion_list.count(\"abusive\")\n",
    "            count_notprank=emotion_list.count(\"Not_Prank\")\n",
    "            count_prank=emotion_list.count(\"prank\")\n",
    "            total = count_prank+count_angry+count_notprank\n",
    "            angry_percentage = count_angry/total*100\n",
    "            prank_percentage = count_prank/total*100\n",
    "            notprank_percentage = count_notprank/total*100\n",
    "            count_list = [angry_percentage,notprank_percentage ,prank_percentage]\n",
    "            for ind, i in enumerate(count_list):\n",
    "                count_list[ind] = \"{}%\".format(i)\n",
    "            result_list = ['Abusive','Not Prank','Prank']\n",
    "            df = pd.DataFrame(zip(result_list,count_list))\n",
    "        except ZeroDivisionError:\n",
    "            count_list = ['0%','0%','0%']\n",
    "            # for ind, i in enumerate(count_list):\n",
    "                # [ind] = \"{}%\".format(i)\n",
    "            result_list = ['Abusive','Not Prank','Prank']\n",
    "            df = pd.DataFrame(zip(result_list,count_list))\n",
    "\n",
    "        \n",
    "        os.remove(audio_file)\n",
    "\n",
    "\n",
    "        # return render_template('result.html', prediction_text='{}'.format(livepredictions[0]))\n",
    "        return render_template('result.html', prediction_text='{}'.format(livepredictions[0]), text_emotion1='{}'.format(df.iloc[0,:].to_string(index=False,header=False)),text_emotion2='{}'.format(df.iloc[1,:].to_string(index=False,header=False)),text_emotion3='{}'.format(df.iloc[2,:].to_string(index=False,header=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @app.route('/results',methods=['POST'])\n",
    "# def results():\n",
    "#     data = request.get_json(force=True)\n",
    "#     prediction = model.predict(data.values())\n",
    "    \n",
    "#     return jsonify(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [25/Aug/2022 18:56:22] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:56:22] \"GET /static/css/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:56:22] \"GET /static/js/main.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:56:22] \"GET /static/images/logo.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:56:22] \"GET /static/images/footer_logo.PNG HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:56:22] \"GET /static/images/favicon.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:56:34] \"GET /predict_ HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:56:34] \"GET /static/css/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:56:34] \"GET /static/js/main.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:56:34] \"GET /static/images/logo.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:56:34] \"GET /static/images/footer_logo.PNG HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:56:45] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:56:45] \"GET /static/css/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:56:45] \"GET /static/js/main.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:56:45] \"GET /static/images/logo.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:56:45] \"GET /static/images/footer_logo.PNG HTTP/1.1\" 304 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solar ambulance\n",
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [25/Aug/2022 18:57:06] \"GET /predict_ HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:57:06] \"GET /static/css/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:57:06] \"GET /static/js/main.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:57:06] \"GET /static/images/logo.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:57:06] \"GET /static/images/footer_logo.PNG HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:57:25] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:57:25] \"GET /static/css/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:57:25] \"GET /static/js/main.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:57:25] \"GET /static/images/logo.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:57:25] \"GET /static/images/footer_logo.PNG HTTP/1.1\" 304 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possible\n",
      "1/1 [==============================] - 0s 77ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [25/Aug/2022 18:57:39] \"GET /predict_ HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:57:39] \"GET /static/css/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:57:39] \"GET /static/js/main.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:57:39] \"GET /static/images/logo.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:57:39] \"GET /static/images/footer_logo.PNG HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:57:43] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:57:43] \"GET /static/css/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:57:43] \"GET /static/images/logo.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:57:43] \"GET /static/js/main.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:57:43] \"GET /static/images/footer_logo.PNG HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:57:54] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:57:54] \"GET /static/css/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:57:54] \"GET /static/images/logo.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:57:54] \"GET /static/js/main.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:57:54] \"GET /static/images/footer_logo.PNG HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:57:54] \"GET /static/images/favicon.png HTTP/1.1\" 304 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are you stupid call an ambulance\n",
      "1/1 [==============================] - 0s 70ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [25/Aug/2022 18:58:06] \"GET /predict_ HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:58:06] \"GET /static/css/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:58:06] \"GET /static/images/logo.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:58:07] \"GET /static/js/main.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2022 18:58:07] \"GET /static/images/footer_logo.PNG HTTP/1.1\" 304 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True,use_reloader=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "metadata": {
   "interpreter": {
    "hash": "75d5fa5647ed718dff6db6e19cb5826cae172c65e0d9788c078b693ea2246e0d"
   }
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "bb8e428c5d184d53ff11d9519987b17636fb5abc5f4f24e4425db8061d68ee4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
